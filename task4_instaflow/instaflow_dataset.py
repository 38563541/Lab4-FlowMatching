"""
InstaFlow Distillation Dataset Loader (Task 4)

Loads (x_0, x_1) pairs for training one-step generators via distillation.
"""

import json
from pathlib import Path

import torch


class InstaFlowDataset(torch.utils.data.Dataset):
    """
    Dataset for loading InstaFlow distillation pairs (x_0, x_1, labels).

    Each sample consists of:
    - x_0: Initial noise sampled from N(0, I)
    - x_1: High-quality sample generated by teacher model
    - label: Class label (if using CFG)

    The student model learns to map x_0 â†’ x_1 in ONE STEP.
    """

    def __init__(self, distill_data_path: str, use_cfg: bool = False):
        """
        Args:
            distill_data_path: Path to directory containing distillation dataset
            use_cfg: Whether the dataset includes class labels
        """
        super().__init__()
        self.distill_data_path = Path(distill_data_path)
        self.use_cfg = use_cfg

        # Load metadata
        metadata_path = self.distill_data_path / "metadata.json"
        if metadata_path.exists():
            with open(metadata_path, "r") as f:
                self.metadata = json.load(f)
            self.num_samples = self.metadata["num_samples"]
            self.num_classes = self.metadata.get("num_classes", None)
        else:
            # Count files if metadata doesn't exist
            x0_files = sorted(self.distill_data_path.glob("*_x0.pt"))
            self.num_samples = len(x0_files)
            self.num_classes = None

        print(f"Loaded InstaFlow distillation dataset from {distill_data_path}")
        print(f"Number of samples: {self.num_samples}")
        if self.use_cfg:
            print(f"Number of classes: {self.num_classes}")

    def __getitem__(self, idx):
        """
        Returns:
            x_0: Initial noise tensor [C, H, W]
            x_1: Teacher-generated sample tensor [C, H, W]
            label: Class label (if use_cfg=True)
        """
        # Load x_0 and x_1
        x_0 = torch.load(self.distill_data_path / f"{idx:06d}_x0.pt")
        x_1 = torch.load(self.distill_data_path / f"{idx:06d}_x1.pt")

        if self.use_cfg:
            label = torch.load(self.distill_data_path / f"{idx:06d}_label.pt")
            return x_0, x_1, label
        else:
            return x_0, x_1

    def __len__(self):
        return self.num_samples


def get_instaflow_data_iterator(iterable):
    """Allows training with DataLoaders in a single infinite loop"""
    iterator = iterable.__iter__()
    while True:
        try:
            yield iterator.__next__()
        except StopIteration:
            iterator = iterable.__iter__()


if __name__ == "__main__":
    # Test the dataset loader
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("--distill_data_path", type=str, required=True)
    parser.add_argument("--use_cfg", action="store_true")
    args = parser.parse_args()

    dataset = InstaFlowDataset(args.distill_data_path, use_cfg=args.use_cfg)
    print(f"Dataset size: {len(dataset)}")

    # Test loading first sample
    if args.use_cfg:
        x_0, x_1, label = dataset[0]
        print(f"x_0 shape: {x_0.shape}, x_1 shape: {x_1.shape}, label: {label}")
    else:
        x_0, x_1 = dataset[0]
        print(f"x_0 shape: {x_0.shape}, x_1 shape: {x_1.shape}")

    # Test dataloader
    dataloader = torch.utils.data.DataLoader(
        dataset, batch_size=4, shuffle=True, num_workers=2
    )
    if args.use_cfg:
        x_0_batch, x_1_batch, label_batch = next(iter(dataloader))
        print(f"Batch shapes: x_0={x_0_batch.shape}, x_1={x_1_batch.shape}, labels={label_batch.shape}")
    else:
        x_0_batch, x_1_batch = next(iter(dataloader))
        print(f"Batch shapes: x_0={x_0_batch.shape}, x_1={x_1_batch.shape}")
